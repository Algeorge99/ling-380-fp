{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaae6acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-07 20:08:48.911396: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-07 20:08:48.911687: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-07 20:08:48.914550: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Importing the relevant modules, also here's the inspo: https://colab.research.google.com/github/dlmacedo/starter-academic/blob/master/content/courses/deeplearning/notebooks/pytorch/Time_Series_Prediction_with_LSTM_Using_PyTorch.ipynb#scrollTo=vIWvJCpOVmwU\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm, json\n",
    "#config = (vocab_size = 30522, hidden_size = 768,\n",
    "#          num_hidden_layers = 12, num_attention_heads = 12,\n",
    "#          intermediate_size = 3072, hidden_act = 'gelu',\n",
    "#          hidden_dropout_prob = 0.1. attention_probs_dropout_prob = 0.1,\n",
    "#          max_position_embeddings = 512, type_vocab_size = 2, initializer_range = 0.02,\n",
    "#          layer_norm_eps = 1e-12, pad_token_id = 0, \n",
    "#          position_embedding_type = 'absolute', use_cache = True,\n",
    "#          classifier_dropout = None**kwargs )\n",
    "\n",
    "#makes inferrence faster\n",
    "configuration = BertConfig(intermediate_size = 2048,  output_hidden_states = True,\n",
    "                           hidden_size = 516, num_hidden_layers = 8)\n",
    "#delete .cuda() if you don't have a good graphics card/it isn't configured to work with training\n",
    "model = BertModel(configuration).cuda()\n",
    "\n",
    "# This is the same tokenizer that\n",
    "# was used in the model to generate\n",
    "# embeddings to ensure consistency\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c4637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3c5bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:00, 54584.90it/s]\n"
     ]
    }
   ],
   "source": [
    "filename = '../yelp_academic_dataset_review.json'\n",
    "reviews = []\n",
    "with open(filename, 'rt') as f:\n",
    "        for line in tqdm.tqdm(f):\n",
    "            data = json.loads(line)\n",
    "\n",
    "            reviews.append({\n",
    "                key: data[key]\n",
    "                for key in ['review_id', 'user_id', 'business_id', 'stars', \"text\"]\n",
    "            })\n",
    "            #rapid development\n",
    "            if len(reviews) > 100: break\n",
    "review_df = pd.DataFrame(reviews)\n",
    "del reviews\n",
    "\n",
    "for cat in review_df.columns:\n",
    "    if cat != \"stars\":\n",
    "        review_df[cat] = review_df[cat].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a69ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "#needed to pad sequences :P\n",
    "text = \"[SEP]\"\n",
    "tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "SEP_EMBEDDING = get_bert_embeddings(tokens_tensor.cuda(), segments_tensors.cuda(), model)[0]\n",
    "\n",
    "def convert_sentence_to_list_embeddings(text, pad_to, tokenizer = tokenizer, seq_length = 512):\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    ret = []\n",
    "    tokens = chunks(tokens_tensor[0].numpy(), seq_length)\n",
    "    segments = chunks(segments_tensors[0].numpy(), seq_length)\n",
    "    for tokens_, segments_ in zip(tokens, segments):\n",
    "        ret+= get_bert_embeddings(torch.Tensor([tokens_]).int().cuda(),\n",
    "                                  torch.tensor([segments_]).int().cuda(), model)\n",
    "    ret += [SEP_EMBEDDING]*(pad_to - len(ret))\n",
    "    return np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "180f52ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "test_df = review_df.head(20)\n",
    "\n",
    "#get pad size\n",
    "max_size = 0\n",
    "for text in test_df[\"text\"]:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    max_size = max(max_size, len(tokenized_text))\n",
    "\n",
    "#create new df\n",
    "test_df[\"seq\"] = test_df[\"text\"].apply(lambda x: convert_sentence_to_list_embeddings(x, pad_to = max_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98f69cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x)\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        \n",
    "        h_out = h_out.view(-1, self.hidden_size)\n",
    "        \n",
    "        out = self.fc(h_out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eff319d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 1.74673581, -1.1778357 ,  1.12215698, ...,  0.48197943,\n",
      "          0.83313698, -0.45976985],\n",
      "        [ 2.36452603, -0.53093255,  0.18928151, ...,  0.55637705,\n",
      "          0.0851301 ,  0.00905598],\n",
      "        [ 0.64944446,  0.37697053,  0.35114574, ...,  0.0204777 ,\n",
      "          1.22808337, -0.59115922],\n",
      "        ...,\n",
      "        [ 0.79090834, -0.40771866, -0.15133946, ..., -0.44330767,\n",
      "          0.4001312 , -1.43794405],\n",
      "        [ 0.01071478,  0.57925272,  1.22340786, ...,  1.7247678 ,\n",
      "          0.47757462, -0.51489353],\n",
      "        [ 2.10566473,  0.40637681,  0.65402728, ..., -0.15148453,\n",
      "          0.25683278, -0.47660798]])\n",
      " array([[ 1.92555225, -0.86355537,  1.78062141, ...,  1.08589649,\n",
      "          0.45323732, -0.37013352],\n",
      "        [ 1.96811426, -1.5662303 ,  0.15587023, ...,  1.18492961,\n",
      "          0.63843763, -0.90759379],\n",
      "        [ 1.10643566, -0.41290733, -0.68686706, ..., -0.25571406,\n",
      "          1.39038324,  0.09403047],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.83541238, -1.22447991,  0.96452397, ...,  1.5537411 ,\n",
      "          0.91252178, -0.39257389],\n",
      "        [ 1.69639945, -0.74599975,  0.74799532, ...,  1.40637267,\n",
      "          0.71045476, -0.03195572],\n",
      "        [ 2.5405724 , -0.39110312, -0.27091616, ...,  0.13292871,\n",
      "         -0.05801738, -1.53790295],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.93894899, -1.26049221,  0.89341372, ...,  1.41885686,\n",
      "          0.85495311, -0.06284641],\n",
      "        [ 1.93049431, -0.35445091,  1.08782446, ...,  0.52728128,\n",
      "         -0.1482805 , -0.61188632],\n",
      "        [ 1.16423428,  0.21475901, -0.13844652, ..., -0.56941086,\n",
      "          1.10676873, -0.75339842],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.78820157, -0.91352123,  0.61499363, ...,  0.91336364,\n",
      "          1.47852874,  0.2731714 ],\n",
      "        [ 1.59602427, -0.80007046,  1.41110718, ...,  0.71745437,\n",
      "          0.24196538, -0.97971296],\n",
      "        [ 1.44261408, -0.29107252,  0.12418819, ...,  0.54730844,\n",
      "          0.93676764, -0.25768846],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.54129088, -0.69220519,  1.23336411, ...,  1.56744754,\n",
      "          0.62018913, -0.09122147],\n",
      "        [ 0.57896054, -1.60795426,  0.18696567, ...,  1.10827649,\n",
      "          0.48357251, -0.45305157],\n",
      "        [ 1.71034694,  0.45114824, -0.28059477, ...,  0.60583824,\n",
      "          1.02949369, -0.75211358],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.94676709, -1.51118076,  1.4310056 , ...,  1.32795393,\n",
      "          1.01936233, -0.53051877],\n",
      "        [ 1.3895545 , -0.77084821,  1.23194385, ...,  0.04197049,\n",
      "          0.10994982, -0.28745162],\n",
      "        [ 2.50876164, -1.00482166, -0.19258721, ..., -0.30385002,\n",
      "          0.29531249, -1.32475448],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 2.11984372, -0.65150243,  0.94690686, ...,  0.04921174,\n",
      "          0.62307906, -0.18219951],\n",
      "        [ 0.33565158, -0.0530739 ,  1.23537946, ...,  0.55571944,\n",
      "          0.56598496, -0.85714948],\n",
      "        [ 1.32598186,  0.10259936,  0.50280392, ..., -0.27349108,\n",
      "          0.68855715, -0.29147139],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.21338367, -0.71785414, -0.02911089, ...,  1.37538147,\n",
      "          0.99986899, -0.64931786],\n",
      "        [ 1.5335182 , -0.36187297,  0.79946297, ...,  0.39369693,\n",
      "          0.30052766, -0.79057288],\n",
      "        [ 1.89219844,  0.44865891,  0.79341418, ..., -0.85315597,\n",
      "          0.23456998, -1.01816249],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.40552938, -0.55061507,  0.66831571, ...,  0.83998966,\n",
      "          0.06926325, -0.09242751],\n",
      "        [ 1.04791617, -0.36676246,  1.32185614, ...,  0.62674981,\n",
      "          0.1377129 , -0.38141334],\n",
      "        [ 1.85660923, -0.12822497, -0.51765859, ..., -1.04579151,\n",
      "          1.60001218,  0.90399599],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.95779538, -1.22972786,  0.82233506, ...,  1.58551848,\n",
      "          1.6284287 ,  0.09715215],\n",
      "        [ 1.85843956,  0.14998688,  1.32000315, ...,  1.57443285,\n",
      "          0.19853257, -0.22180203],\n",
      "        [ 1.22582269, -0.25271589,  0.38789812, ..., -0.16581082,\n",
      "          1.46324837, -0.11037632],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 2.08915854, -1.44519258,  1.32531846, ...,  0.77213061,\n",
      "          0.91905141, -0.39596936],\n",
      "        [ 1.10179138, -1.23524034,  0.52910119, ...,  0.14009835,\n",
      "          1.12269199, -0.54676795],\n",
      "        [ 0.06940137, -0.56006342, -0.17819662, ...,  1.4753089 ,\n",
      "          1.24395478, -0.23249297],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.49829769, -0.88587379,  1.32206821, ...,  1.2063849 ,\n",
      "          0.56348091, -0.08531726],\n",
      "        [ 1.19975543, -0.46603215,  0.1957179 , ...,  1.15390623,\n",
      "          0.14194064, -0.42678642],\n",
      "        [ 2.5638926 ,  0.2842418 , -0.01016471, ...,  0.62816495,\n",
      "          0.99448538, -0.72130734],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 2.28692079, -0.42216963,  0.91460127, ...,  0.6518904 ,\n",
      "          0.92988545, -0.31937268],\n",
      "        [ 1.41547132, -0.44317743,  1.0032804 , ...,  0.24103974,\n",
      "          0.38002896, -0.73658526],\n",
      "        [ 1.50865924, -0.41734695,  0.95694983, ...,  0.51084328,\n",
      "          0.27693999, -0.91678888],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.58110464, -0.65250933, -0.42451045, ...,  1.24656773,\n",
      "          1.0922358 , -0.3279134 ],\n",
      "        [ 1.46287835, -1.55660021,  0.03985865, ...,  0.93918353,\n",
      "          0.70496535, -1.02277994],\n",
      "        [ 1.84132779,  0.18920207, -1.4217577 , ..., -0.10329623,\n",
      "          1.30232263, -1.57633245],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.47228837, -1.18905866,  0.95271993, ...,  0.98930949,\n",
      "          1.10557902, -0.14390858],\n",
      "        [ 2.64516473,  0.10979436,  0.0044142 , ...,  0.34419638,\n",
      "         -0.16221985, -0.58593428],\n",
      "        [ 2.28995609,  0.08913019, -0.32986441, ...,  0.11723232,\n",
      "          0.23408662, -1.38408017],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.73301136, -0.99410874,  0.26866418, ...,  0.89125133,\n",
      "          0.99596006, -0.55345255],\n",
      "        [ 1.93428051, -0.50615078,  0.80590039, ...,  0.09403727,\n",
      "          0.90512282, -0.33081719],\n",
      "        [ 1.77974975,  0.95739859, -0.46890476, ...,  0.00953243,\n",
      "          0.86915934, -0.67203051],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.67046106, -1.09863162,  0.97194648, ...,  1.32585871,\n",
      "          1.18951833, -0.72692537],\n",
      "        [ 2.396487  , -0.8565014 ,  0.00805411, ...,  1.61297321,\n",
      "          0.18566516,  0.44095328],\n",
      "        [ 2.51227546, -1.41061282,  0.75119638, ..., -0.54805785,\n",
      "          0.99321187, -0.93559086],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 1.88424253, -0.3965005 ,  0.01595605, ...,  1.63490772,\n",
      "          1.03897715, -0.03244111],\n",
      "        [ 1.67949367, -0.41419169,  0.44754779, ...,  0.66070205,\n",
      "          1.1036979 , -0.44002676],\n",
      "        [ 1.04905367, -0.48358923,  0.52272058, ..., -0.11545222,\n",
      "          1.54914296, -0.66784674],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])\n",
      " array([[ 2.32508421, -0.56650686,  0.36301059, ...,  1.49049902,\n",
      "          1.22631168, -0.01296631],\n",
      "        [ 1.16476309, -0.34194523,  0.94686425, ...,  0.66919917,\n",
      "         -0.28694704, -1.03585911],\n",
      "        [ 0.42275098,  0.18492471,  0.38476139, ..., -1.60963702,\n",
      "          0.07549123,  0.14547728],\n",
      "        ...,\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964],\n",
      "        [ 1.67387819, -0.91761404,  0.90260994, ...,  1.30245197,\n",
      "          0.77364987, -0.15612964]])                             ]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_76677/3095283844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seq\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/InnovationIndex/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_76677/1685722436.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         h_0 = Variable(torch.zeros(\n\u001b[0;32m---> 23\u001b[0;31m             self.num_layers, x.size(0), self.hidden_size))\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         c_0 = Variable(torch.zeros(\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "num_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "input_size = 516\n",
    "hidden_size = 256\n",
    "num_layers = 1\n",
    "\n",
    "num_classes = 1\n",
    "\n",
    "lstm = LSTM(num_classes, input_size, hidden_size, num_layers, max_size)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = lstm(test_df[\"seq\"].values)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # obtain the loss function\n",
    "    loss = criterion(outputs, trainY)\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da09a841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
